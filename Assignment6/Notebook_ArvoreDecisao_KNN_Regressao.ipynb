{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3460EU0Fc9D"
   },
   "source": [
    "# Tarefa 6 - Árvore de decisão e KNN com Regressão\n",
    "\n",
    "####**Dicas:**\n",
    "\n",
    "- Tutorial para iniciantes em Python: https://www.datacamp.com/cheat-sheet/getting-started-with-python-cheat-sheet\n",
    "\n",
    "- Documentação do pandas: https://colab.research.google.com/drive/1a4sbKG7jOJGn4oeonQPA8XjJm7OYgcdX\n",
    "\n",
    "- Documentação do scikit-learn: https://scikit-learn.org/stable/\n",
    "\n",
    "- Documentação do matplotlib: https://matplotlib.org/stable/index.html\n",
    "\n",
    "- Documentação do seaborn: https://seaborn.pydata.org/tutorial.html\n",
    "\n",
    "---\n",
    "## **Sobre o dataset:**\n",
    "\n",
    "Este dataset contém informações sobre o uso de bicicletas de aluguel em cidades urbanas, incluindo dados meteorológicos, como temperatura, umidade, velocidade do vento, visibilidade, ponto de orvalho, radiação solar, queda de neve e precipitação. Ele permite prever a quantidade de bicicletas necessárias a cada hora, facilitando a disponibilidade e acessibilidade para os usuários.\n",
    "\n",
    "**Colunas:**\n",
    "\n",
    "- **Rented Bike Count** - Contagem de bicicletas alugadas a cada hora **(target)**\n",
    "\n",
    "- **Hour** - Hora do dia\n",
    "- **Temperature** - Temperatura em Celsius\n",
    "- **Humidity** - %\n",
    "- **Windspeed** - m/s\n",
    "- **Visibility** - 10m\n",
    "- **Dew point temperature** - Temperatura do ponto de orvalho em Celsius\n",
    "- **Solar radiation** - MJ/m²\n",
    "- **Rainfall** - mm\n",
    "- **Snowfall** - cm\n",
    "- **Seasons** - Inverno, Primavera, Verão, Outono\n",
    "- **Holiday** - Feriado/Sem feriado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzhGRQJUFdCB"
   },
   "source": [
    "## **Importe os pacotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNBdcSiRFdHB"
   },
   "source": [
    "## **Crie os datasets**\n",
    "### **Crie um DataFrame a partir do arquivo de dados disponibilizados no EaD**\n",
    "\n",
    "**Dicas:**\n",
    "\n",
    "* Certifique-se que os arquivos a serem lidos estão carregados na sua sessão do Colab, ou em um drive previamente montado, e ajuste o comando para incluir todo o caminho até cada um dos arquivos a serem lidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'SeoulBikeData.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Seasons.unique())\n",
    "print(df.Holiday.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG7QgqxbFdMY"
   },
   "source": [
    "## **Pré-Processamento dos Dados**\n",
    "\n",
    "Aplique as técnicas de pré-processamento que vimos em aula no dataset fornecido.\n",
    "\n",
    "### **Dicas:**\n",
    "- **Converter dados categóricos para numéricos:** Use `LabelEncoder` ou `OneHotEncoder`.\n",
    "\n",
    "- **Transformar os dados:** Experimente `MinMaxScaler` para ajustar a escala dos dados.\n",
    "\n",
    "- **Remover outliers:** Verifique outliers com base no IQR e os elimine se necessário.\n",
    "\n",
    "- **Tratar valores nulos:** Preencha com a média, moda, mediana ou remova as linhas, dependendo do impacto no dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_holiday = LabelEncoder()\n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform='pandas')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def pre_processing(df: pd.DataFrame, remove_outliers: bool, first_time=True):\n",
    "    if first_time:\n",
    "        df['Holiday'] = le_holiday.fit_transform(df['Holiday'])\n",
    "        seasons = ohe.fit_transform(df[['Seasons']])\n",
    "        df = pd.concat([df, seasons], axis=1)\n",
    "        df.drop(columns=['Seasons'], axis = 1, inplace = True)\n",
    "        df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    else:\n",
    "        df['Holiday'] = le_holiday.transform(df['Holiday'])\n",
    "        seasons = ohe.transform(df[['Seasons']])\n",
    "        df = pd.concat([df, seasons], axis=1)\n",
    "        df.drop(columns=['Seasons'], axis = 1, inplace = True)\n",
    "        df[df.columns] = scaler.transform(df[df.columns])\n",
    "\n",
    "    if remove_outliers:\n",
    "        # as outras colunas ou não possuem outliers ou zeram o DataFrame\n",
    "        for col in ['Rented Bike Count', 'Wind speed (m/s)', 'Solar Radiation (MJ/m2)']:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "\n",
    "    # df não possui valores nulos\n",
    "    return df\n",
    "\n",
    "df = pre_processing(df=df, remove_outliers=True)\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtYYP7ySFdQ6"
   },
   "source": [
    "# **Criação de Conjuntos de Treinamento, Teste e Validação**\n",
    "\n",
    "Divida os dados em conjuntos de treino, validação e teste. Para isso, selecione aleatoriamente 70% dos registros, sem reposição, para o conjunto de treinamento. Os 30% restantes deverão ser divididos igualmente entre os conjuntos de validação e teste.\n",
    "\n",
    "Dicas:\n",
    "- Fixe a semente de geração de dados aleatórios, utilize o comando `np.random.seed(escolha um número)`, antes de executar qualquer célula de comando que possa variar de valor resultante toda vez que for executada.\n",
    "\n",
    "- Para fazer a divisão de treino, validação, teste use a função `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = df.drop('Rented Bike Count', axis=1)\n",
    "y = df['Rented Bike Count']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.70)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqdZU0zqFdWS"
   },
   "source": [
    "# **Treine e Teste o Modelo de Árvore de Decisão**\n",
    "\n",
    "Treinar três versões diferentes do modelo de Árvore de Decisão utilizando valores variados para a sua profundidade.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "- Busque pela função `DecisionTreeRegressor(max_depth=?)` da biblioteca scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [3, 6, 9]\n",
    "trees = []\n",
    "\n",
    "for depth in depths:\n",
    "    regressor = DecisionTreeRegressor(max_depth=depth, min_samples_leaf=10)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_val_pred = regressor.predict(X_val)\n",
    "\n",
    "    trees.append({ \n",
    "        'model': regressor,\n",
    "        'depth': depth,\n",
    "        'pred': y_val_pred\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YINwE_SMFdbP"
   },
   "source": [
    "# **Avaliação do Modelo**\n",
    "\n",
    "Neste momento, é importante avaliar cada um dos modelos gerados utilizando o **dataset de validação**. Apresente as métricas de erro quadrático médio (MSE), erro absoluto médio (MAE), e coeficiente de determinação (R²) para cada modelo.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "- Você pode usar a função `mean_squared_error(_, _)` da biblioteca `scikitlearn.metrics` e, para calcular as demais métricas do modelo, busque pelas funções `mean_absolute_error()` e `r2_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in trees:\n",
    "    tree['MSE'] = mean_squared_error(y_val, tree['pred'])\n",
    "    tree['MAE'] = mean_absolute_error(y_val, tree['pred'])\n",
    "    tree['R2'] = r2_score(y_val, tree['pred'])\n",
    "\n",
    "    print(f'Tree of depth {tree[\"depth\"]}:')\n",
    "    print(f'• MSE: {tree[\"MSE\"]}')\n",
    "    print(f'• MAE: {tree[\"MAE\"]}')\n",
    "    print(f'• R2: {tree[\"R2\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etYsHeCyHGRU"
   },
   "source": [
    "# **Feature Importance**\n",
    "\n",
    "Gere o gráfico de importância das features para o modelo que obteve o melhor desempenho nos dados de validação. Em seguida, remova as **cinco** features com menor importância e treine o modelo novamente.\n",
    "\n",
    "**Dica**\n",
    "\n",
    "- Utilize o método `.feature_importances_` da biblioteca `sklearn` para obter os valores de importância de cada feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trees[1]['model']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "importances = best_model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "sorted_importances = importances[indices]\n",
    "sorted_features = features[indices]\n",
    "\n",
    "plt.bar(sorted_features, sorted_importances)\n",
    "\n",
    "plt.xticks(rotation=65)\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_important_features = ['Dew point temperature', 'Seasons_Summer', 'Snowfall (cm)', 'Seasons_Winter', 'Holiday']\n",
    "\n",
    "X_train.drop(columns=least_important_features, inplace=True)\n",
    "X_val.drop(columns=least_important_features, inplace=True)\n",
    "X_test.drop(columns=least_important_features, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRsAJQd_HGkT"
   },
   "source": [
    "# **Avaliação do Novo Modelo**\n",
    "\n",
    "Com as cinco features removidas, treine novamente o modelo de árvore de decisão escolhido, e o avalie novamente utilizando apenas o **conjunto de validação**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 6\n",
    "regressor = DecisionTreeRegressor(max_depth=depth, min_samples_leaf=10)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_val_pred = regressor.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'• MSE: {mse}')\n",
    "print(f'• MAE: {mae}')\n",
    "print(f'• R2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pNLbix8yTyv"
   },
   "source": [
    "# **Plotar a árvore do melhor modelo**\n",
    "\n",
    "Gere a visualização da Árvore de Decisão do novo modelo\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "- Use a função `plot_tree()` da biblioteca `sklearn`\n",
    "\n",
    "- Para tornar a visualização mais clara e facilitar a interpretação dos resultados, ajuste o parâmetro max_depth em `plot_tree(max_depth=?)`, limitando a profundidade da árvore exibida e destacando os nós mais significativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80, 15))\n",
    "plot_tree(regressor, filled=True, feature_names=regressor.feature_names_in_)\n",
    "\n",
    "plt.savefig('decision_tree_regressor_full.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6))\n",
    "plot_tree(regressor, max_depth=3, filled=True)\n",
    "\n",
    "plt.savefig('decision_tree_regressor.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXqjV4tqylUp"
   },
   "source": [
    "# **Criação de Exemplos Fictícios**\n",
    "\n",
    "Observe a estrutura da árvore de decisão treinada e crie dois exemplos fictícios com valores de entrada diferentes. Para cada exemplo, descreva detalhadamente o caminho que ele seguirá na árvore, ou seja, a sequência de nós que serão percorridos até chegar à folha correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame(data={\n",
    "    'Rented Bike Count': [112, 1753], # Valores não representativos do conjunto de dados\n",
    "    'Hour': [0, 20], \n",
    "    'Temperature': [-7.2, 18.8], \n",
    "    'Humidity(%)': [37, 40], \n",
    "    'Wind speed (m/s)': [2.2, 0.9], \n",
    "    'Visibility (10m)': [2000, 2000], \n",
    "    'Dew point temperature': [-17.6, 5.7], \n",
    "    'Solar Radiation (MJ/m2)': [0.0, 0.0], \n",
    "    'Rainfall(mm)': [0.0, 0.0], \n",
    "    'Snowfall (cm)': [0.0, 0.0], \n",
    "    'Seasons': ['Spring', 'Autumn'], \n",
    "    'Holiday': ['No Holiday', 'Holiday']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pre_processing(df=example_df, remove_outliers=False, first_time=False)\n",
    "example_df['Seasons_Summer'] = [0.0, 0.0] # Seasons_Summer e Seasons_Winter não são criados automaticamente pelo OneHotEncoder\n",
    "example_df['Seasons_Winter'] = [0.0, 0.0]\n",
    "example_df.drop(least_important_features, axis=1, inplace=True)\n",
    "example_df.head()\n",
    "\n",
    "# TODO: consertar discrepância entre análise da árvore e valores preditos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFFuX6sHymWA"
   },
   "source": [
    "# **Inferência e Verificação**\n",
    "\n",
    "Realize uma inferência utilizando esses dois exemplos fictícios no modelo treinado. Verifique se os resultados obtidos na inferência correspondem aos valores do target que você imaginou ao criar os exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.predict(example_df.drop('Rented Bike Count', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQnNRgA4HHcQ"
   },
   "source": [
    "# **Treine e Teste o Modelo de KNN**\n",
    "\n",
    "Treinar três versões diferentes do modelo K-Nearest Neighbors (KNN) utilizando valores variados para o parâmetro K.\n",
    "\n",
    "**Dica:**\n",
    "- Busque pela função `KNeighborsRegressor(n_neighbors=?)` da biblioteca `scikitlearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 5, 7]\n",
    "knn_models = []\n",
    "\n",
    "for k in k_values:\n",
    "    regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_val_pred = regressor.predict(X_val)\n",
    "\n",
    "    knn_models.append({ \n",
    "        'model': regressor,\n",
    "        'k': k,\n",
    "        'pred': y_val_pred\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8c5SUGSHHg5"
   },
   "source": [
    "# **Avaliação do Modelo**\n",
    "\n",
    "Neste momento, é importante avaliar cada um dos modelos gerados utilizando o **dataset de validação**. Apresente as métricas de erro quadrático médio (MSE), erro absoluto médio (MAE), e coeficiente de determinação (R²) para cada modelo.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "- Você pode usar a função `mean_squared_error()` da biblioteca `scikitlearn.metrics` e, para calcular as demais métricas do modelo, busque pelas funções `mean_absolute_error()` e `r2_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for knn in knn_models:\n",
    "    knn['MSE'] = mean_squared_error(y_val, knn['pred'])\n",
    "    knn['MAE'] = mean_absolute_error(y_val, knn['pred'])\n",
    "    knn['R2'] = r2_score(y_val, knn['pred'])\n",
    "\n",
    "    print(f'KNN with {knn[\"k\"]} neighbors:')\n",
    "    print(f'• MSE: {knn[\"MSE\"]}')\n",
    "    print(f'• MAE: {knn[\"MAE\"]}')\n",
    "    print(f'• R2: {knn[\"R2\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7kF50u5HHek"
   },
   "source": [
    "# **Escolha do melhor modelo**\n",
    "\n",
    "Selecione o melhor modelo até agora com base no desempenho no conjunto de validação (KNN ou a Árvore de Decisão; a avaliação determinará a escolha) e avalie-o no **conjunto de** **teste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = trees[1]\n",
    "print(f'Best tree (depth {best_tree[\"depth\"]}):')\n",
    "print(f'• MSE: {best_tree[\"MSE\"]}')\n",
    "print(f'• MAE: {best_tree[\"MAE\"]}')\n",
    "print(f'• R2: {best_tree[\"R2\"]}\\n')\n",
    "\n",
    "best_knn = knn_models[1]\n",
    "print(f'Best KNN ({best_knn[\"k\"]} neighbors):')\n",
    "print(f'• MSE: {best_knn[\"MSE\"]}')\n",
    "print(f'• MAE: {best_knn[\"MAE\"]}')\n",
    "print(f'• R2: {best_knn[\"R2\"]}\\n')\n",
    "\n",
    "print(f'The best model is the tree of depth {best_tree[\"depth\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7XxfLHDHHix"
   },
   "source": [
    "# **Mostre uma análise comparativa entre validação e teste para o modelo escolhido**\n",
    "\n",
    "**Observação:** Se houver uma discrepância muito grande nos resultados, algo pode estar errado, verifique seu treinamento e avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation set predictions:')\n",
    "print(f'• MSE: {best_tree[\"MSE\"]}')\n",
    "print(f'• MAE: {best_tree[\"MAE\"]}')\n",
    "print(f'• R2: {best_tree[\"R2\"]}\\n')\n",
    "\n",
    "print('Test set predictions:')\n",
    "print(f'• MSE: {mean_squared_error(y_test, y_test_pred)}')\n",
    "print(f'• MAE: {mean_absolute_error(y_test, y_test_pred)}')\n",
    "print(f'• R2: {r2_score(y_test, y_test_pred)}\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
